{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f480a66",
   "metadata": {},
   "source": [
    "# Aula 8 - Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653dbdf3",
   "metadata": {},
   "source": [
    "## Revisão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e71bc8",
   "metadata": {},
   "source": [
    "### Acessar um tabela Hive via pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8a91b",
   "metadata": {},
   "source": [
    "Criar o contexto `HiveContext`:\n",
    "\n",
    "    from pyspark.sql import HiveContext\n",
    "    contexto = HiveContext(sc)\n",
    "\n",
    "\n",
    "Conectar o banco de dados na tabela:\n",
    "\n",
    "    banco = contexto.table(\"hr.jobs\")\n",
    "    banco.show()\n",
    "\n",
    "Vamos registra a tabela no spark para ficar disponível para execução de querys\n",
    "\n",
    "    banco.registerTempTable(\"jobs\")\n",
    "    contexto.sql('Select * from jobs').show()\n",
    "    contexto.sql('Select *  from jobs order by salario_max DESC limit 1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9f1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f195be8",
   "metadata": {},
   "source": [
    "### Criar um dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cbe09c",
   "metadata": {},
   "source": [
    "A variável `jobs` é nosso dataframe\n",
    "\n",
    "    jobs = contexto.sql(\"select * from jobs\") \n",
    "    jobs.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e227472",
   "metadata": {},
   "source": [
    "### Alguns comandos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d677c139",
   "metadata": {},
   "source": [
    "    jobs.show(100)\n",
    "    jobs.printSchema()\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d82a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3535ea9",
   "metadata": {},
   "source": [
    "# Iniciando o pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0f909",
   "metadata": {},
   "source": [
    "Para instalar `pyspark` localmente, execute em uma célula:\n",
    "\n",
    "    pip install pyspark\n",
    "    \n",
    "    \n",
    "**ATENÇÂO:** Se a célula abaixo falhar, poser ser necessário instalar o Java na sua máquina e reiniciar o compurador!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eceebef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97fd97cb",
   "metadata": {},
   "source": [
    "Para que o pyspark funcione, é preciso criar e configurar um ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e54035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:07.635937Z",
     "start_time": "2021-08-27T18:09:03.683663Z"
    }
   },
   "outputs": [],
   "source": [
    "# importar as funções\n",
    "from pyspark import sql, SparkContext, HiveContext\n",
    "\n",
    "# criar o sparkcontext\n",
    "sc = SparkContext()\n",
    "\n",
    "# criar a sessão spark\n",
    "spark = sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0108a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:08.310324Z",
     "start_time": "2021-08-27T18:09:08.295746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-DSIGSC0F.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd7fbd44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:09.325936Z",
     "start_time": "2021-08-27T18:09:08.567529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-DSIGSC0F.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x215ef33f130>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b011608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6ca600a",
   "metadata": {},
   "source": [
    "# Acessar arquivo csv com pyspark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03baa7",
   "metadata": {},
   "source": [
    "## Criar uma variável RDD a partir do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547a54a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:11.650269Z",
     "start_time": "2021-08-27T18:09:10.410701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,Public Accountant,4200.00,9000.00',\n",
       " '2,Accounting Manager,8200.00,16000.00',\n",
       " '3,Administration Assistant,3000.00,6000.00',\n",
       " '4,President,20000.00,40000.00',\n",
       " '5,Administration Vice President,15000.00,30000.00',\n",
       " '6,Accountant,4200.00,9000.00',\n",
       " '7,Finance Manager,8200.00,16000.00',\n",
       " '8,Human Resources Representative,4000.00,9000.00',\n",
       " '9,Programmer,4000.00,10000.00',\n",
       " '10,Marketing Manager,9000.00,15000.00',\n",
       " '11,Marketing Representative,4000.00,9000.00',\n",
       " '12,Public Relations Representative,4500.00,10500.00',\n",
       " '13,Purchasing Clerk,2500.00,5500.00',\n",
       " '14,Purchasing Manager,8000.00,15000.00',\n",
       " '15,Sales Manager,10000.00,20000.00',\n",
       " '16,Sales Representative,6000.00,12000.00',\n",
       " '17,Shipping Clerk,2500.00,5500.00',\n",
       " '18,Stock Clerk,2000.00,5000.00',\n",
       " '19,Stock Manager,5500.00,8500.00']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = sc.textFile(\"data/jobs.csv\")\n",
    "jobs.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370613ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78d4feca",
   "metadata": {},
   "source": [
    "## Acessar um arquivo csv via pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c654ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:15.651512Z",
     "start_time": "2021-08-27T18:09:12.819616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+\n",
      "|country_id|country_name|region_id|\n",
      "+----------+------------+---------+\n",
      "|        AR|   Argentina|        2|\n",
      "|        AU|   Australia|        3|\n",
      "|        BE|     Belgium|        1|\n",
      "|        BR|      Brazil|        2|\n",
      "|        CA|      Canada|        2|\n",
      "|        CH| Switzerland|        1|\n",
      "|        CN|       China|        3|\n",
      "|        DE|     Germany|        1|\n",
      "|        DK|     Denmark|        1|\n",
      "|        EG|       Egypt|        4|\n",
      "|        FR|      France|        1|\n",
      "|        HK|    HongKong|        3|\n",
      "|        IL|      Israel|        4|\n",
      "|        IN|       India|        3|\n",
      "|        IT|       Italy|        1|\n",
      "|        JP|       Japan|        3|\n",
      "|        KW|      Kuwait|        4|\n",
      "|        MX|      Mexico|        2|\n",
      "|        NG|     Nigeria|        4|\n",
      "|        NL| Netherlands|        1|\n",
      "+----------+------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countires = spark.read.csv(\"data/countries.csv\", header=True)\n",
    "countires.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73138536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7e701a9",
   "metadata": {},
   "source": [
    "## Adicionar headers quando não estão presentes no arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45def50b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:16.005296Z",
     "start_time": "2021-08-27T18:09:15.653442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+--------+\n",
      "|_c0|                 _c1|     _c2|     _c3|\n",
      "+---+--------------------+--------+--------+\n",
      "|  1|   Public Accountant| 4200.00| 9000.00|\n",
      "|  2|  Accounting Manager| 8200.00|16000.00|\n",
      "|  3|Administration As...| 3000.00| 6000.00|\n",
      "|  4|           President|20000.00|40000.00|\n",
      "|  5|Administration Vi...|15000.00|30000.00|\n",
      "|  6|          Accountant| 4200.00| 9000.00|\n",
      "|  7|     Finance Manager| 8200.00|16000.00|\n",
      "|  8|Human Resources R...| 4000.00| 9000.00|\n",
      "|  9|          Programmer| 4000.00|10000.00|\n",
      "| 10|   Marketing Manager| 9000.00|15000.00|\n",
      "| 11|Marketing Represe...| 4000.00| 9000.00|\n",
      "| 12|Public Relations ...| 4500.00|10500.00|\n",
      "| 13|    Purchasing Clerk| 2500.00| 5500.00|\n",
      "| 14|  Purchasing Manager| 8000.00|15000.00|\n",
      "| 15|       Sales Manager|10000.00|20000.00|\n",
      "| 16|Sales Representative| 6000.00|12000.00|\n",
      "| 17|      Shipping Clerk| 2500.00| 5500.00|\n",
      "| 18|         Stock Clerk| 2000.00| 5000.00|\n",
      "| 19|       Stock Manager| 5500.00| 8500.00|\n",
      "+---+--------------------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data/jobs.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59b8d85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:16.173402Z",
     "start_time": "2021-08-27T18:09:16.006275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+-----------+\n",
      "|indice|           job_title|salario_min|salario_max|\n",
      "+------+--------------------+-----------+-----------+\n",
      "|     1|   Public Accountant|     4200.0|     9000.0|\n",
      "|     2|  Accounting Manager|     8200.0|    16000.0|\n",
      "|     3|Administration As...|     3000.0|     6000.0|\n",
      "|     4|           President|    20000.0|    40000.0|\n",
      "|     5|Administration Vi...|    15000.0|    30000.0|\n",
      "|     6|          Accountant|     4200.0|     9000.0|\n",
      "|     7|     Finance Manager|     8200.0|    16000.0|\n",
      "|     8|Human Resources R...|     4000.0|     9000.0|\n",
      "|     9|          Programmer|     4000.0|    10000.0|\n",
      "|    10|   Marketing Manager|     9000.0|    15000.0|\n",
      "|    11|Marketing Represe...|     4000.0|     9000.0|\n",
      "|    12|Public Relations ...|     4500.0|    10500.0|\n",
      "|    13|    Purchasing Clerk|     2500.0|     5500.0|\n",
      "|    14|  Purchasing Manager|     8000.0|    15000.0|\n",
      "|    15|       Sales Manager|    10000.0|    20000.0|\n",
      "|    16|Sales Representative|     6000.0|    12000.0|\n",
      "|    17|      Shipping Clerk|     2500.0|     5500.0|\n",
      "|    18|         Stock Clerk|     2000.0|     5000.0|\n",
      "|    19|       Stock Manager|     5500.0|     8500.0|\n",
      "+------+--------------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importar arquivos de suporte\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, FloatType\n",
    "\n",
    "# criar schema\n",
    "schema = StructType() \\\n",
    "      .add(\"indice\",IntegerType(),True) \\\n",
    "      .add(\"job_title\",StringType(),True) \\\n",
    "      .add(\"salario_min\",FloatType(),True) \\\n",
    "      .add(\"salario_max\",FloatType(),True) \n",
    "\n",
    "# ler o arquivo\n",
    "df = spark.read.csv(\"data/jobs.csv\", schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d656e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b41d791",
   "metadata": {},
   "source": [
    "# Analíses com pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd585f",
   "metadata": {},
   "source": [
    "## select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbaa65ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:25.251662Z",
     "start_time": "2021-08-27T18:09:25.119531Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|           job_title|salario_min|\n",
      "+--------------------+-----------+\n",
      "|   Public Accountant|     4200.0|\n",
      "|  Accounting Manager|     8200.0|\n",
      "|Administration As...|     3000.0|\n",
      "|           President|    20000.0|\n",
      "|Administration Vi...|    15000.0|\n",
      "|          Accountant|     4200.0|\n",
      "|     Finance Manager|     8200.0|\n",
      "|Human Resources R...|     4000.0|\n",
      "|          Programmer|     4000.0|\n",
      "|   Marketing Manager|     9000.0|\n",
      "|Marketing Represe...|     4000.0|\n",
      "|Public Relations ...|     4500.0|\n",
      "|    Purchasing Clerk|     2500.0|\n",
      "|  Purchasing Manager|     8000.0|\n",
      "|       Sales Manager|    10000.0|\n",
      "|Sales Representative|     6000.0|\n",
      "|      Shipping Clerk|     2500.0|\n",
      "|         Stock Clerk|     2000.0|\n",
      "|       Stock Manager|     5500.0|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('job_title', 'salario_min').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104493f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f59f2a0",
   "metadata": {},
   "source": [
    "## filter e/ou where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286db165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:09:28.839350Z",
     "start_time": "2021-08-27T18:09:28.655761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+-----------+-----------+\n",
      "|indice|           job_title|salario_min|salario_max|\n",
      "+------+--------------------+-----------+-----------+\n",
      "|     4|           President|    20000.0|    40000.0|\n",
      "|     5|Administration Vi...|    15000.0|    30000.0|\n",
      "+------+--------------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.salario_min >=15000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65bba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df61dade",
   "metadata": {},
   "source": [
    "## sum, min, max, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "267f7cc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:13:32.969036Z",
     "start_time": "2021-08-27T18:13:32.823552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|sum(salario_min)|\n",
      "+----------------+\n",
      "|        124800.0|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('salario_min').where(df.salario_min>=0).groupby().sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf0e227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83a9aa5a",
   "metadata": {},
   "source": [
    "## agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22265b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:13:09.840784Z",
     "start_time": "2021-08-27T18:13:09.710812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|sum(salario_min)|\n",
      "+----------------+\n",
      "|        124800.0|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'salario_min': 'sum'}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7408ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2efdfd4f",
   "metadata": {},
   "source": [
    "## [join](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.join.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f27b4a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:16:23.920746Z",
     "start_time": "2021-08-27T18:16:23.732164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------+--------------------+------------+----------+------+--------+----------+-------------+\n",
      "|employee_id| first_name| last_name|               email|phone_number| hire_date|job_id|  salary|manager_id|department_id|\n",
      "+-----------+-----------+----------+--------------------+------------+----------+------+--------+----------+-------------+\n",
      "|        100|     Steven|      King|steven.king@sqltu...|515.123.4567|1987-06-17|     4|24000.00|      null|            9|\n",
      "|        101|      Neena|   Kochhar|neena.kochhar@sql...|515.123.4568|1989-09-21|     5|17000.00|       100|            9|\n",
      "|        102|        Lex|   De Haan|lex.de haan@sqltu...|515.123.4569|1993-01-13|     5|17000.00|       100|            9|\n",
      "|        103|  Alexander|    Hunold|alexander.hunold@...|590.423.4567|1990-01-03|     9| 9000.00|       102|            6|\n",
      "|        104|      Bruce|     Ernst|bruce.ernst@sqltu...|590.423.4568|1991-05-21|     9| 6000.00|       103|            6|\n",
      "|        105|      David|    Austin|david.austin@sqlt...|590.423.4569|1997-06-25|     9| 4800.00|       103|            6|\n",
      "|        106|      Valli| Pataballa|valli.pataballa@s...|590.423.4560|1998-02-05|     9| 4800.00|       103|            6|\n",
      "|        107|      Diana|   Lorentz|diana.lorentz@sql...|590.423.5567|1999-02-07|     9| 4200.00|       103|            6|\n",
      "|        108|      Nancy| Greenberg|nancy.greenberg@s...|515.124.4569|1994-08-17|     7|12000.00|       101|           10|\n",
      "|        109|     Daniel|    Faviet|daniel.faviet@sql...|515.124.4169|1994-08-16|     6| 9000.00|       108|           10|\n",
      "|        110|       John|      Chen|john.chen@sqltuto...|515.124.4269|1997-09-28|     6| 8200.00|       108|           10|\n",
      "|        111|     Ismael|   Sciarra|ismael.sciarra@sq...|515.124.4369|1997-09-30|     6| 7700.00|       108|           10|\n",
      "|        112|Jose Manuel|     Urman|jose manuel.urman...|515.124.4469|1998-03-07|     6| 7800.00|       108|           10|\n",
      "|        113|       Luis|      Popp|luis.popp@sqltuto...|515.124.4567|1999-12-07|     6| 6900.00|       108|           10|\n",
      "|        114|        Den|  Raphaely|den.raphaely@sqlt...|515.127.4561|1994-12-07|    14|11000.00|       100|            3|\n",
      "|        115|  Alexander|      Khoo|alexander.khoo@sq...|515.127.4562|1995-05-18|    13| 3100.00|       114|            3|\n",
      "|        116|     Shelli|     Baida|shelli.baida@sqlt...|515.127.4563|1997-12-24|    13| 2900.00|       114|            3|\n",
      "|        117|      Sigal|    Tobias|sigal.tobias@sqlt...|515.127.4564|1997-07-24|    13| 2800.00|       114|            3|\n",
      "|        118|        Guy|    Himuro|guy.himuro@sqltut...|515.127.4565|1998-11-15|    13| 2600.00|       114|            3|\n",
      "|        119|      Karen|Colmenares|karen.colmenares@...|515.127.4566|1999-08-10|    13| 2500.00|       114|            3|\n",
      "+-----------+-----------+----------+--------------------+------------+----------+------+--------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ler tabela employees\n",
    "df_emp = spark.read.csv(\"data/employees.csv\", header=True)\n",
    "df_emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a956f4fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-27T18:30:24.106507Z",
     "start_time": "2021-08-27T18:30:23.872018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+-----------+-----------+\n",
      "|  salary|job_id|           job_title|salario_min|salario_max|\n",
      "+--------+------+--------------------+-----------+-----------+\n",
      "|24000.00|     4|           President|    20000.0|    40000.0|\n",
      "|17000.00|     5|Administration Vi...|    15000.0|    30000.0|\n",
      "|17000.00|     5|Administration Vi...|    15000.0|    30000.0|\n",
      "| 9000.00|     9|          Programmer|     4000.0|    10000.0|\n",
      "| 6000.00|     9|          Programmer|     4000.0|    10000.0|\n",
      "| 4800.00|     9|          Programmer|     4000.0|    10000.0|\n",
      "| 4800.00|     9|          Programmer|     4000.0|    10000.0|\n",
      "| 4200.00|     9|          Programmer|     4000.0|    10000.0|\n",
      "|12000.00|     7|     Finance Manager|     8200.0|    16000.0|\n",
      "| 9000.00|     6|          Accountant|     4200.0|     9000.0|\n",
      "| 8200.00|     6|          Accountant|     4200.0|     9000.0|\n",
      "| 7700.00|     6|          Accountant|     4200.0|     9000.0|\n",
      "| 7800.00|     6|          Accountant|     4200.0|     9000.0|\n",
      "| 6900.00|     6|          Accountant|     4200.0|     9000.0|\n",
      "|11000.00|    14|  Purchasing Manager|     8000.0|    15000.0|\n",
      "| 3100.00|    13|    Purchasing Clerk|     2500.0|     5500.0|\n",
      "| 2900.00|    13|    Purchasing Clerk|     2500.0|     5500.0|\n",
      "| 2800.00|    13|    Purchasing Clerk|     2500.0|     5500.0|\n",
      "| 2600.00|    13|    Purchasing Clerk|     2500.0|     5500.0|\n",
      "| 2500.00|    13|    Purchasing Clerk|     2500.0|     5500.0|\n",
      "+--------+------+--------------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join\n",
    "df_emp.join(df, on=df_emp.job_id==df.indice, how='left')\\\n",
    "    .select(df_emp.salary, df_emp.job_id, df.job_title, df.salario_min, df.salario_max)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6faf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
