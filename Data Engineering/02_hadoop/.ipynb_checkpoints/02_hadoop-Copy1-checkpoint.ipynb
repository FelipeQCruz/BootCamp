{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df70f38",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a13eca",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## O que é ?\n",
    "Hadoop é um framework em código aberto para armazenamento e processamento distribuídos de grandes conjuntos de dados em hardware simples.\n",
    "![Hadoop](https://s3-sa-east-1.amazonaws.com/lcpi/e6813617-b661-41ae-83c5-916651ce42e9.png)\n",
    "\n",
    "## História\n",
    "Motivado a construir um buscador complexo, que funcione na escala da web, indexando bilhões de páginas, Doug Cutting resolveu se dedicar ao desafio iniciando seu projeto Nutch junto com Mike Cafarella, mas enfrentou alguns problemas com escalabilidade.\n",
    "\n",
    "Hadoop era o nome do elefante amarelo de pelúcia do filho de Doug.\n",
    "\n",
    "Um artigo publicado em 2003 pelo Google abriu caminho para que a equipe do Nutch criasse uma implementação open source do GFS (Google File System).\n",
    "\n",
    "Em 2004 o Google publica o clássico artigo descrevendo seu framework MapReduce para atender às necessidades de processamento de várias máquinas das tarefas de rastreamento e índice.\n",
    "\n",
    "## Onde usar Hadoop?\n",
    "- Análise de Dados\n",
    "- Data Warehouse\n",
    "- Data Lake\n",
    "- Processamento de logs\n",
    "- Muito mais!\n",
    "\n",
    "## Características\n",
    "- Baixo custo \n",
    "- Flexibilidade de armazenamento\n",
    "- OpenSource\n",
    "- Tolerante a falha\n",
    "- Análise complexa de dados\n",
    "- Escalabilidade\n",
    "\n",
    "## Componentes\n",
    "- Hadoop Common\n",
    "- HDFS (Hadoop File System)\n",
    "- MapReduce\n",
    "- Yarn\n",
    "\n",
    "## Replicação\n",
    "A alta disponibilidade de dados no Hadoop é possível devido à replicação implícita de dados em um cluster Hadoop. Um bloco de arquivo é replicado em vários \"nós de dados\" com base no \"fator de replicação\" do cluster Hadoop, que pode ser 1, 2, 3 ...\n",
    "\n",
    "Um fator de replicação 1 indica que um bloco de arquivos residirá em um único \"nó de dados\". Um fator de replicação 2 indica que um bloco de arquivos residirá em dois \"nós de dados\", no mesmo rack ou em um fisicamente a milhares de quilômetros de distância; etc.\n",
    "\n",
    "## Arquitetura\n",
    "O Hadoop é baseado em uma arquitetura Master/Slave. Um cluster Hadoop possui um único nó Master e vários nós Slaves.\n",
    "\n",
    "### Master\n",
    "É responsável por armazenar os metadados associados aos seus nós slaves no rack do qual faz parte.\n",
    "\n",
    "O nó principal é responsável por manter o status de seus nós slaves, estabelecendo um deles como um nó passivo, que se tornará um nó principal se, por qualquer motivo, estiver bloqueado. Um dos problemas do Hadoop é que às vezes o nó passivo não é sincronizado com o nó principal original , assumindo suas funções no processo.\n",
    "\n",
    "### Slave\n",
    "É o nó encarregado de armazenar as informações que estão sendo processadas pelo nó master em um momento específico.\n",
    "\n",
    "## Hadoop Common\n",
    "Também conhecido como Hadoop Core, é a coleção de utilitários comuns e bibliotecas (JAR) que oferecem suporte a outros módulos Hadoop, sendo assim vital para sua inicialização e funcionamento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cec82f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "369ad255",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198d21e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hadoop Distributed File System (HDFS) é o sistema de armazenamento distribuído utilizado por aplicações Hadoop. O HDFS quebra os arquivos em blocos de dados (128 MB por padrão), cria réplicas (três por padrão) e as ditribui no cluster, permitindo assim computações extremamente rápidas em arquivos pequenos e em máquinas distintas. HDFS permite escalabilidade e tolerança a falhas\n",
    "\n",
    "## Componentes\n",
    "\n",
    "- NameNode: Gerencia o namespace do sistema de arquivos do Hadoop.\n",
    "- DataNode: Armazena os blocos de dados em um nó.\n",
    "\n",
    "### NameNode\n",
    "- Armazena metadados.\n",
    "- Usa cache em RAM para acesso mais rápido ao metadado.\n",
    "- Não armazena dados.\n",
    "- Apenas 1 ativo por cluster.\n",
    "- Ponto único de falha sem HA (Alta Disponibilidade).\n",
    "\n",
    "Em resumo, o NameNode faz a gestão do HDFS em um nó: mantém metadados, logs, adiciona, encontra, exclui e copia arquivos. \n",
    "\n",
    "### DataNode\n",
    "- Armazena os dados no HDFS.\n",
    "- Atende solicitações de leitura e gravação dos clientes ou NameNode.\n",
    "- Responsável por criar, excluir e replicar blocos de dados.\n",
    "- Reportar status para o NameNode (heartbeat).\n",
    "- Em caso de falta de report o nó é desativado pelo NameNode.\n",
    "- Totalmente dependente do NameNode.\n",
    "\n",
    "Em resumo, o DataNode mantém dados e replica blocos.\n",
    "\n",
    "## Prática!\n",
    "Criar um diretório no HDFS:\n",
    "~~~\n",
    "hdfs dfs -mkdir /user/cloudera/aula\n",
    "~~~\n",
    "Listar o conteúdo do diretório do HDFS:\n",
    "~~~\n",
    "hdfs dfs -ls /user/cloudera/aula\n",
    "~~~\n",
    "crie um arquivo:\n",
    "~~~\n",
    "vim hadoop.txt\n",
    "~~~\n",
    "\n",
    "Inserir arquivo no HDFS a partir do FileSystem:\n",
    "~~~\n",
    "hdfs dfs -put hadoop.txt /user/cloudera/aula\n",
    "hdfs dfs -ls /user/cloudera/aula\n",
    "~~~\n",
    "\n",
    "Visualizar conteúdo do arquivo no HDFS:\n",
    "~~~\n",
    "hdfs dfs -cat /user/cloudera/aula/hadoop.txt\n",
    "hdfs dfs -tail /user/cloudera/aula/hadoop.txt\n",
    "~~~\n",
    "\n",
    "Mover arquivo dentro do HDFS:\n",
    "~~~\n",
    "hdfs dfs -mv /user/cloudera/aula/hadoop.txt /user/cloudera/\n",
    "~~~\n",
    "\n",
    "Copiar arquivo dentro do HDFS:\n",
    "~~~\n",
    "hdfs dfs -cp /user/cloudera/hadoop.txt /user/cloudera/aula\n",
    "~~~\n",
    "\n",
    "Remover arquivo do HDFS:\n",
    "~~~\n",
    "hdfs dfs -rm /user/cloudera/aula/hadoop.txt\n",
    "~~~\n",
    "\n",
    "Copiar arquivo do HDFS para o FileSystem:\n",
    "~~~\n",
    "hdfs dfs -get /user/cloudera/hadoop.txt /tmp/\n",
    "~~~\n",
    "\n",
    "Localização do blocos no HDFS:\n",
    "~~~\n",
    "hdfs fsck /user/cloudera/hadoop.txt  -blocks -files -locations\n",
    "~~~\n",
    "\n",
    "Aumentar quantidade de réplicas:\n",
    "~~~\n",
    "hdfs dfs -setrep 2 /user/cloudera/hadoop.txt\n",
    "~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a010fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aee22b3e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Interface Web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69adaa",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Overview\n",
    "~~~\n",
    "http://quickstart.cloudera:50070\n",
    "~~~\n",
    "![Overview](https://s3-sa-east-1.amazonaws.com/lcpi/9197b966-1c13-4e45-9b19-78dd366f4c9a.JPG)\n",
    "\n",
    "## Hue\n",
    "~~~\n",
    "http://quickstart.cloudera:8888\n",
    "~~~\n",
    "![Hue](https://s3-sa-east-1.amazonaws.com/lcpi/e6813617-b661-41ae-83c5-916651ce42e9.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe299d4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3df1e0b8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MapReduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3b36d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "O Hadoop MapReduce é um modelo de programação para criação de aplicações processam rapidamente vastas quantidades de dados em paralelo através de grandes clusters de computadores comuns.\n",
    "\n",
    "O código ou programa a ser executado, é transportado até o local do dado, executando tarefas independentes em cada bloco de dado (Map), e depois são consolidados gerando a resposta do processamento (Reduce).\n",
    "\n",
    "Estrutura de uma aplicação MapReduce.\n",
    "\n",
    "- Map: Atua exclusivamente sobre um conjunto de entrada com chaves e valores, produzindo uma lista de chaves e valores.\n",
    "- Reduce: Atua sobre os valores intermediários produzidos pelo map para, normalmente, agrupar os valores e produzir uma saída.\n",
    "\n",
    "O processo, de forma simplificada:\n",
    "\n",
    "- Dados são divididos em blocos\n",
    "- Divisão de problemas grandes e/ou complexos em pequenas tarefas\n",
    "- Mapeamento é executado em paralelo nos nós\n",
    "- Apenas quando o Mapeamento é encerrado, redução inicia, também em paralelo\n",
    "- Fase intermediária: Shuffle (distribui as saídas dos mappers para a execução do reducer)\n",
    "- Existem tarefa que requerem apenas a etapa de Mapeamento.\n",
    "\n",
    "## Map\n",
    "Atua exclusivamente sobre um conjunto de entrada com chaves e valores,\n",
    "produzindo uma lista de chaves e valores\n",
    "\n",
    "Características:\n",
    "- Ponto de partida\n",
    "- Recebe cada registro dos dados de entrada como pares de chave/valor\n",
    "- Cada Mapper é independente um do outro, permitindo paralelismo e re-execuções de tarefas\n",
    "- Hadoop cria tarefas de Mapper para cada bloco de dados HDFS dos dados de entrada.\n",
    "- Produz uma lista de chave/valor\n",
    "\n",
    "## Reduce\n",
    "Atua sobre os valores intermediários produzidos pelo map para, normalmente, agrupar os valores e produzir uma saída.\n",
    "\n",
    "Características:\n",
    "- Responsável por agregações, filtros e combinações diversas nos dados de entrada\n",
    "- Executa uma função de reduce por vez\n",
    "- Shuffle: Distribui as saídas dos mappers para a execução do reducer\n",
    "- Sort: Ordena os registros chave/valor, agrupando pela chave\n",
    "- Reduce: Envia os conjuntos chave/valor agrupados, filtrados ou combinados o formato de saída\n",
    "\n",
    "## Pontos Positivos\n",
    "- Escalável\n",
    "- Tolerante a falhas\n",
    "- Disponibilidade\n",
    "- Confiável\n",
    "- Usa conceito de chave/valor\n",
    "- Não cria gargalos na rede pois os dados não trafegam (processamento no nó)\n",
    "\n",
    "## Pontos Negativos\n",
    "MapReduce não é indicado para:\n",
    "- Consultas que necessitam de baixa latência\n",
    "- Sistemas real-time\n",
    "- Consultas em um website\n",
    "- Processamento de pequenas tarefas\n",
    "- Overhead para gerenciamento das tarefas\n",
    "\n",
    "## Prática!\n",
    "Download\n",
    "~~~\n",
    "https://s3-sa-east-1.amazonaws.com/lcpi/c6729d53-18cb-4f16-b1b7-e0217c57649a.zip\n",
    "~~~\n",
    "\n",
    "Criar um diretório no HDFS:\n",
    "~~~\n",
    "hadoop fs -mkdir /user/cloudera/input\n",
    "~~~\n",
    "\n",
    "Inserir arquivo no HDFS a partir do FileSystem\n",
    "~~~\n",
    "hadoop fs -put texto.csv /user/cloudera/input\n",
    "~~~\n",
    "\n",
    "Executando MapReduce\n",
    "~~~\n",
    "hadoop jar wordcount.jar WordCount /user/cloudera/input /user/cloudera/output\n",
    "~~~\n",
    "\n",
    "Verificar Job\n",
    "~~~\n",
    "http://quickstart.cloudera:8088\n",
    "~~~\n",
    "\n",
    "Ver lista os arquivos no diretório no HDFS:\n",
    "~~~\n",
    "hadoop fs -ls /user/cloudera/output\n",
    "~~~\n",
    "\n",
    "Verificando o conteúdo do arquivo:\n",
    "~~~\n",
    "hadoop fs -cat /user/cloudera/output/part-r-00000\n",
    "~~~\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc6239",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3178cf7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Yarn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383de7b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "O YARN foi introduzido no Hadoop versão 2.0 no ano de 2012 pelo Yahoo e Hortonworks. A idéia básica por trás do YARN é aliviar o MapReduce, assumindo a responsabilidade do Gerenciamento de Recursos e do Agendamento de Tarefas. O YARN começou a dar ao Hadoop a capacidade de executar tarefas não MapReduce na estrutura do Hadoop. \n",
    "\n",
    "Características:\n",
    "- Permite que vários aplicativos sejam executados simultaneamente no mesmo cluster compartilhado.\n",
    "- Permite que os aplicativos negociem recursos com base na necessidade.\n",
    "\n",
    "## Arquitetura\n",
    "Duas principais funcionalidades: gerenciamento de recursos e agendamento/monitoramento de tarefas\n",
    "Componentes:\n",
    "- ResourceManager: um por cluster (orquestrador)\n",
    "    - ApplicationManager: gerencia atividades, otimização, distribuição de recursos.\n",
    "- NodeManager: um por nó, responsável pela execução dos Jobs.\n",
    "- Aplication Master: Distribui tarefas aos containers.\n",
    "- Container: mantém as tarefas.\n",
    "\n",
    "## ResourceManager\n",
    "- Possui um agendador de nível de cluster que tem responsabilidade pela alocação de recursos para todas as tarefas em execução, de acordo com as solicitações do ApplicationManager.\n",
    "- A principal responsabilidade do ResourceManager é alocar recursos para os aplicativos.\n",
    "- Não é responsável pelo rastreamento do status de uma aplicação ou tarefas de monitoramento.\n",
    "- Não garante o reinício/balanceamento de tarefas no caso de falha no aplicativo ou no hardware.\n",
    "\n",
    "## NodeManager\n",
    "- Nó Slave, é executado nos worker nodes.\n",
    "- Gerencia o ciclo de vida do container e monitora o uso de recursos.\n",
    "- Executa o container com base na capacidade do nó, que é calculada com base na memória instalada e no número de núcleos da CPU.\n",
    "- Envia um sinal ao para atualizar seu status de integridadeResourceManager.\n",
    "- Envia o status para ResourceManager, que pode ser o status do nó ou o status das tarefas executadas.\n",
    "\n",
    "## ApplicationMaster\n",
    "- Biblioteca de aplicativos que gerencia cada instância de um aplicativo que é executado dentro de YARN.\n",
    "- Responsável por negociar recursos do ResourceManager na submissão do aplicativo, como memória e CPU.\n",
    "- Responsável por monitorar o status de um aplicativo e monitorar os processos de aplicativos em coordenação com o NodeManager.\n",
    "\n",
    "## Container\n",
    "- Pacote lógico de recursos em termos de memória, CPU, disco, etc...\n",
    "- Vinculado a um nó específico\n",
    "- ResourceManager aloca dinamicamente recursos como containeres\n",
    "- Um container concede direitos a um ApplicationMaster para usar uma quantidade específica de recursos de um host específico\n",
    "- ApplicationMaster é considerado como o primeiro container de um aplicativo e gerência a execução da lógica do aplicativo em containers alocados\n",
    "\n",
    "## Prática!\n",
    "Verificar Jobs:\n",
    "~~~\n",
    "http://quickstart.cloudera:8088/\n",
    "~~~\n",
    "\n",
    "Os comandos YARN são invocados usando o script bin/yarn no pacote Hadoop\n",
    "\n",
    "A sintaxe básica para o comando:\n",
    "~~~\n",
    "yarn [--config confdir] COMMAND COMMAND_OPTIONS\n",
    "~~~\n",
    "\n",
    "Application: Lista, obter status e mata um aplicativo:\n",
    "~~~\n",
    "yarn application -list\n",
    "yarn application -status application_1507835793432_0005\n",
    "yarn application -kill application_1507835793432_0005\n",
    "~~~\n",
    "Node: Lista e obter status dos nós\n",
    "~~~\n",
    "yarn node –list\n",
    "yarn node -all -list\n",
    "yarn node -status quickstart.cloudera:47512\n",
    "~~~\n",
    "Logs: Obtem logs de um aplicativo já finalizado\n",
    "~~~\n",
    "yarn logs -applicationId application_1507835793432_0005\n",
    "~~~\n",
    "Classpath: retorna o valor do classpath atual\n",
    "~~~\n",
    "yarn classpath\n",
    "~~~\n",
    "Version: retorna a versão atual do Cluster Yarn\n",
    "~~~\n",
    "yarn version\n",
    "~~~\n",
    "Top: Fornece um resumo de informações:\n",
    "~~~\n",
    "yarn top\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffaeb2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
